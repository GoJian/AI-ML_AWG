{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxHtljhGULio"
   },
   "source": [
    "The purpose of this notebook is to combine all retina data from the [Rodent Research 9](https://osdr.nasa.gov/bio/repo/data/payloads/RR-9) (RR9) mission from the [NASA Open Science Data Repository](https://www.nasa.gov/osdr/ (OSDR)), perform exploratory data analysis, and train a digital twin.\n",
    "\n",
    "Testing needs to be done to see whether a larger synthetic dataset should be generated prior to digital twin training; and the ML model for the digital twin has not been identified yet.\n",
    "\n",
    "Future work could also include incorporating the raw image data from [OSD-568](https://osdr.nasa.gov/bio/repo/data/studies/OSD-568) and [OSD-557](https://osdr.nasa.gov/bio/repo/data/studies/OSD-557), and environmental data from RR-9 (https://visualization.osdr.nasa.gov/eda/).\n",
    "\n",
    "\n",
    "Feel free to make a copy of this notebook and change or add to it. Fill in your name below.\n",
    "\n",
    "**Original Author:** Lauren Sanders\n",
    "\n",
    "**Additional Author(s):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6pthy2l7GNW"
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "Combine and merge 5 RR-9 datasets with different measurements on the mouse retina. Not all measurements are available for all samples (see the [RR9 Sample and Dataset sheet](https://docs.google.com/spreadsheets/d/1uZbj4rXpEWZJDywE7HAvwR5v7RNDtVyG/edit?gid=1036112252#gid=1036112252)).\n",
    "\n",
    "1. [OSD-255](https://osdr.nasa.gov/bio/repo/data/studies/OSD-255): Gene expression quantification through RNA sequencing (right eye).\n",
    "\n",
    "2. [OSD-568](https://osdr.nasa.gov/bio/repo/data/studies/OSD-568): Immunostaining quantification of 2 molecular markers related to blood-retinal barrier integrity: ZO1 and PECAM; and quantification of DNA damage from the TUNEL assay (left eye).\n",
    "\n",
    "3. [OSD-557](https://osdr.nasa.gov/bio/repo/data/studies/OSD-557): Quantification of the [structure of the eye using microCT](https://pubmed.ncbi.nlm.nih.gov/33191924/); and immunostaining quantification of [PNA, a molecular marker for eye cone degradation](https://www.nature.com/articles/s41598-019-49453-x); and quantification of [H&E stain](https://en.wikipedia.org/wiki/H%26E_stain) for different cell components (left eye).\n",
    "\n",
    "4. [OSD-583](https://osdr.nasa.gov/bio/repo/data/studies/OSD-583): Quantification of intra-ocular pressure through tonometry (both eyes).\n",
    "\n",
    "5. [OSD-715](https://osdr.nasa.gov/bio/repo/data/studies/OSD-715): Protein expression quantification through mass spectrometry (left eye)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CxVHofq6LllG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from skimpy import skim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from feature_engine.imputation import RandomSampleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import plotly.express as px\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MBmA7KZIwhCu"
   },
   "outputs": [],
   "source": [
    "## Using the Data API from the OSDR Public API\n",
    "## Documentation: https://www.nasa.gov/reference/osdr-public-api/\n",
    "\n",
    "rnaseq = pd.read_csv('https://osdr.nasa.gov/geode-py/ws/studies/OSD-255/download?source=datamanager&file=GLDS-255_rna_seq_Normalized_Counts.csv', index_col=0).transpose()\n",
    "\n",
    "zo1 = pd.read_csv('https://osdr.nasa.gov/geode-py/ws/studies/OSD-568/download?source=datamanager&file=LSDS-5_immunostaining_microscopy_Zo-1tr_TRANSFORMED.csv')\n",
    "\n",
    "tunel = pd.read_csv('https://osdr.nasa.gov/geode-py/ws/studies/OSD-568/download?source=datamanager&file=LSDS-5_immunostaining_microscopy_TUNELtr_TRANSFORMED.csv')\n",
    "\n",
    "pecam = pd.read_csv('https://osdr.nasa.gov/geode-py/ws/studies/OSD-568/download?source=datamanager&file=LSDS-5_immunostaining_microscopy_PECAMtr_TRANSFORMED.csv')#['Source Name']=['F15','F16','F17','F18','F19','F20','GC15','GC16','GC17','GC18','GC19']\n",
    "\n",
    "microct = pd.read_csv('https://osdr.nasa.gov/geode-py/ws/studies/OSD-557/download?source=datamanager&file=LSDS-1_microCT_MicroCT_Transformed_Reusable_Results.csv') #NOTE: OSD-557 also has raw image files for immunostaining and H&E\n",
    "\n",
    "pna = pd.read_csv('https://osdr.nasa.gov/geode-py/ws/studies/OSD-557/download?source=datamanager&file=LSDS-1_immunostaining_microscopy_PNAtr_Transformed_Reusable_Results.csv')\n",
    "\n",
    "hne = pd.read_csv('https://osdr.nasa.gov/geode-py/ws/studies/OSD-557/download?source=datamanager&file=LSDS-1_immunostaining_microscopy_HNEtr_Transformed_Reusable_Results.csv')\n",
    "\n",
    "tonometry = pd.read_csv('https://osdr.nasa.gov/geode-py/ws/studies/OSD-583/download?source=datamanager&file=LSDS-16_tonometry_maoTRANSFORMED.csv')\n",
    "\n",
    "protein = pd.read_excel('https://osdr.nasa.gov/geode-py/ws/studies/OSD-715/download?source=datamanager&file=GLDS-639_proteomics_01_Mao_RR9_Retina_092018_MQ_iBAQ.xlsx', sheet_name='Combat corrected', index_col=0).transpose()\n",
    "protein = protein.drop(protein.columns[[0, 1, 2, 4, 5, 6]], axis=1).rename(columns={\"Sample\": \"Source Name\"}).reset_index().drop(columns=['index']) # remove some Excel formatting\n",
    "protein = protein.set_index('Source Name').apply(pd.to_numeric, errors='coerce') # convert to numeric instead of dtype \"object\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qh-owcJ3rmAP",
    "outputId": "80bc78d2-7405-415c-d0dc-7345f1d53c4f"
   },
   "outputs": [],
   "source": [
    "print(rnaseq.shape)\n",
    "print(protein.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b02WygSurfUH",
    "outputId": "1853ce82-9268-44a2-c113-672748f53009"
   },
   "outputs": [],
   "source": [
    "# Filter omics data:\n",
    "# - remove genes and proteins with greater than 1% zero values\n",
    "# - keep 1000 genes and 1000 proteins with highest variance\n",
    "\n",
    "rnaseq = rnaseq.loc[:, (rnaseq == 0).mean() < 0.01]  # Remove features with too many zeros\n",
    "print(rnaseq.shape)\n",
    "rnaseq = rnaseq.loc[:, rnaseq.var().nlargest(1000).index]  # Take top 1000 features by variance\n",
    "\n",
    "protein = protein.loc[:, (protein == 0).mean() < 0.01]  # Remove features with too many zeros\n",
    "print(protein.shape)\n",
    "protein = protein.loc[:, protein.var().nlargest(1000).index]  # Take top 1000 features by variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tVuQWr70hsqq"
   },
   "outputs": [],
   "source": [
    "all_genes = rnaseq.columns.tolist() # get all gene names for later\n",
    "all_proteins = protein.columns.tolist() # get all protein names for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oDGRKo5PpxdM"
   },
   "outputs": [],
   "source": [
    "# Add Source Name to all the dfs that are missing it\n",
    "# Rename some Source Names that already exist\n",
    "\n",
    "#Fviv = CC1 (confirmed in OSD-583 metadata)\n",
    "#GViv = CC2?\n",
    "\n",
    "gsm_dict = {\n",
    "    \"GSM3932702\": \"F11\",\n",
    "    \"GSM3932703\": \"F15\",\n",
    "    \"GSM3932704\": \"F16\",\n",
    "    \"GSM3932705\": \"F17\",\n",
    "    \"GSM3932706\": \"F18\",\n",
    "    \"GSM3932707\": \"F19\",\n",
    "    \"GSM3932708\": \"F20\",\n",
    "    \"GSM3932694\": \"GC11\",\n",
    "    \"GSM3932695\": \"GC15\",\n",
    "    \"GSM3932696\": \"GC16\",\n",
    "    \"GSM3932697\": \"GC17\",\n",
    "    \"GSM3932698\": \"GC18\",\n",
    "    \"GSM3932699\": \"GC19\",\n",
    "    \"GSM3932700\": \"GC20\",\n",
    "    \"GSM3932693\": \"GC9\",\n",
    "    \"GSM3932701\": \"F9\"\n",
    "}\n",
    "\n",
    "rnaseq['Source Name'] = rnaseq.index.map(gsm_dict)\n",
    "\n",
    "zo1['Source Name'] = ['F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'GC15', 'GC16', 'GC17', 'GC18', 'GC19', 'GC20']\n",
    "\n",
    "tunel['Source Name'] = ['F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'GC15', 'GC16', 'GC17', 'GC18', 'GC19', 'GC20', 'CC2_15', 'CC2_16', 'CC2_17', 'CC2_18', 'CC2_20', 'Viv15', 'Viv16', 'Viv17', 'Viv18', 'Viv19', 'Viv20'] #rename VG to CC2 and V to Viv for consistency\n",
    "\n",
    "pecam['Source Name'] = ['F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'GC15', 'GC16', 'GC17', 'GC18', 'GC19']\n",
    "\n",
    "microct['Source Name'] = ['F10', 'F12', 'F13', 'F14', 'Viv10', 'Viv12', 'Viv13', 'Viv14', 'GC10', 'GC11', 'GC13', 'GC14'] #rename V to Viv\n",
    "\n",
    "hne['Source Name'] = [\"F15\", \"F16\", \"F17\", \"F18\", \"F19\", \"F20\", \"GC15\", \"GC16\", \"GC17\", \"GC18\", \"GC19\", \"Viv15\", \"Viv16\", \"Viv17\", \"Viv18\", \"Viv19\", \"Viv20\", \"CC2_15\", \"CC2_16\", \"CC2_17\", \"CC2_18\", \"CC2_19\", \"CC2_20\"]\n",
    "\n",
    "tonometry['Source Name'] = [\"F1\", \"F2\", \"F3\", \"F4\", \"F5\", \"F6\", \"F7\", \"F8\", \"F9\", \"F10\", \"F11\", \"F12\", \"F13\", \"F14\", \"F15\", \"F16\", \"F17\", \"F18\", \"F19\", \"F20\", \"CC1_1\", \"CC1_2\", \"CC1_3\", \"CC1_4\", \"CC1_5\", \"CC1_6\", \"CC1_7\", \"CC1_8\", \"CC1_9\", \"CC1_10\", \"CC1_11\", \"CC1_12\", \"CC1_13\", \"CC1_14\", \"CC1_15\", \"CC1_16\", \"CC1_17\", \"CC1_18\", \"CC1_19\", \"CC1_20\", \"GC1\", \"GC2\", \"GC3\", \"GC4\", \"GC5\", \"GC6\", \"GC7\", \"GC8\", \"GC9\", \"GC10\", \"GC11\", \"GC12\", \"GC13\", \"GC14\", \"GC15\", \"GC16\", \"GC17\", \"GC18\", \"GC19\", \"GC20\", \"Viv1\", \"Viv2\", \"Viv3\", \"Viv4\", \"Viv5\", \"Viv6\", \"Viv7\", \"Viv8\", \"Viv9\", \"Viv10\", \"Viv11\", \"Viv12\", \"Viv13\", \"Viv14\", \"Viv15\", \"Viv16\", \"Viv17\", \"Viv18\", \"Viv19\", \"Viv20\", \"CC2_1\", \"CC2_2\", \"CC2_3\", \"CC2_4\", \"CC2_5\", \"CC2_6\", \"CC2_7\", \"CC2_8\", \"CC2_9\", \"CC2_10\", \"CC2_11\", \"CC2_12\", \"CC2_13\", \"CC2_14\", \"CC2_15\", \"CC2_16\", \"CC2_17\", \"CC2_18\", \"CC2_19\", \"CC2_20\"] #rename \"FViv\" to \"CC1\"  for consistency\n",
    "\n",
    "protein['Source Name'] = protein.index\n",
    "protein.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MLqcmbOly96G"
   },
   "outputs": [],
   "source": [
    "# Drop \"Sample Name\" and a couple other irrelevant columns\n",
    "zo1.drop(columns=['Sample_Name'], inplace=True)\n",
    "tunel.drop(columns=['Sample_Name'], inplace=True)\n",
    "pecam.drop(columns=['Sample_Name'], inplace=True)\n",
    "microct.drop(columns=['Sample Name', 'Treatment'], inplace=True)\n",
    "pna.drop(columns=['Sample Name', 'Treatment'], inplace=True)\n",
    "hne.drop(columns=['Sample Name'], inplace=True)\n",
    "tonometry.drop(columns=['Sample Name', 'Factor Value: Spaceflight', 'time_Start', 'Time_End'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QaNtIiFvvlsG"
   },
   "outputs": [],
   "source": [
    "# Add suffix to all physiological data column names to avoid duplicates (rnaseq and protein should be unique)\n",
    "zo1.columns = [col + '_zo1' if col != 'Source Name' else col for col in zo1.columns]\n",
    "tunel.columns = [col + '_tunel' if col != 'Source Name' else col for col in tunel.columns]\n",
    "pecam.columns = [col + '_pecam' if col != 'Source Name' else col for col in pecam.columns]\n",
    "microct.columns = [col + '_microct' if col != 'Source Name' else col for col in microct.columns]\n",
    "pna.columns = [col + '_pna' if col != 'Source Name' else col for col in pna.columns]\n",
    "hne.columns = [col + '_hne' if col != 'Source Name' else col for col in hne.columns]\n",
    "tonometry.columns = [col + '_tonometry' if col != 'Source Name' else col for col in tonometry.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yirrdyRY7Oca"
   },
   "source": [
    "## Merge dataframes\n",
    "\n",
    "Merge all dataframes on the \"Source Name\" column, filling empty data values with \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dV1gCPDjtCCG",
    "outputId": "a98c02fe-9448-4c12-9431-e79af02f08e3"
   },
   "outputs": [],
   "source": [
    "dfs = [rnaseq, protein, zo1, tunel, pecam, microct, pna, hne, tonometry]\n",
    "\n",
    "# Convert 'Source Name' to string in all DataFrames to avoid dtype conflicts\n",
    "for df in dfs:\n",
    "    df['Source Name'] = df['Source Name'].astype(str)\n",
    "\n",
    "# Merge all DataFrames on \"Source Name\" column\n",
    "merged_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on=\"Source Name\", how=\"outer\")\n",
    "\n",
    "# Move source name column to the front\n",
    "column_to_move = merged_df.pop(\"Source Name\")\n",
    "merged_df.insert(0, \"Source Name\", column_to_move)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# skim(merged_df.head())\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "teSkni5jK1gr"
   },
   "outputs": [],
   "source": [
    "all_phys = [x for x in merged_df.drop(columns='Source Name').columns if x not in all_genes and x not in all_proteins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Xy4vfZPUsKDt"
   },
   "outputs": [],
   "source": [
    "# Add a group column\n",
    "merged_df['Group'] = [\n",
    "    \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\",\n",
    "    \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\", \"CC1\",\n",
    "    \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\",\n",
    "    \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\", \"CC2\",\n",
    "    \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\",\n",
    "    \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\",\n",
    "    \"GC\", \"GC\", \"GC\", \"GC\", \"GC\", \"GC\", \"GC\", \"GC\", \"GC\", \"GC\",\n",
    "    \"GC\", \"GC\", \"GC\", \"GC\", \"GC\", \"GC\", \"GC\", \"GC\", \"GC\", \"GC\",\n",
    "    \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\",\n",
    "    \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\", \"Viv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr6g3BcgYA_j"
   },
   "source": [
    "---\n",
    "There are 5 different experimental groups within the dataset: CC1, CC2, F, GC, and Viv. Definitions are below.\n",
    "\n",
    "**CC1** = (cohort control 1) Due to Hurricane Irma’s impact on KSC in September, 2017, experiments with both GC and GV (Viv) control groups were cancelled and later rescheduled for May, 2018, using mice of the same strain, sex, age and animals were from the same holding room from the vendor that were used for the flight experiments. This resulted in a large time gap between tissue collection for the flight and KSC ground control groups. Consequently, the FV (CC1) cohort-matched control group was added to the study to help control for possible differences associated with this delay.\n",
    "\n",
    "**CC2** = (cohort control 2) Ground cohort-matched control group.\n",
    "\n",
    "**F** = (flight) mice housed on the International Space Station for 35 days.\n",
    "\n",
    "**GC** = (ground control) matched cohort to the flight mice; lived on Earth the duration of the mission in flight habitats.\n",
    "\n",
    "**Viv** = (vivarium) matched cohort to the flight mice; lived on Earth the duration of the mission in normal vivarium habitats.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWCa8y7PtuiC"
   },
   "source": [
    "## Scale the data\n",
    "\n",
    "Since the RNAseq data is on a very different scale from the rest of the data, scale the whole dataset between 0-1 for comparability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jamz8Q8psMIU",
    "outputId": "23eab446-f097-4919-8726-6f6c136e3769"
   },
   "outputs": [],
   "source": [
    "# What's the max value in the merged data?\n",
    "\n",
    "merged_df.drop('Group', axis=1).set_index('Source Name').max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pXdL9MV-tAEp"
   },
   "outputs": [],
   "source": [
    "## Plot histogram distribution of all numerical values in the merged data\n",
    "\n",
    "# Select only numeric columns and flatten them into a single list, ignoring NaN values\n",
    "numeric_values = merged_df.select_dtypes(include=np.number).values.flatten()\n",
    "numeric_values = numeric_values[~np.isnan(numeric_values)]  # Remove NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrWTt30Auc_p",
    "outputId": "9d9d4f2f-e699-415c-9306-c141b632380d"
   },
   "outputs": [],
   "source": [
    "len(numeric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "p8CDYaScuapm",
    "outputId": "8db045b5-fcc2-43df-a68e-be95fa00634f"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "plt.hist(numeric_values, bins=100) #1000 without variance filtering\n",
    "plt.title(\"Histogram of All Numeric Values in DataFrame\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JHlAVYqItBu2"
   },
   "outputs": [],
   "source": [
    "# Min-Max scale the data\n",
    "scaler = MinMaxScaler()\n",
    "df = merged_df.drop('Group', axis=1).set_index('Source Name')\n",
    "merged_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8bRdIQMu5Gk",
    "outputId": "892fbefa-d27e-4331-df53-bc70c68ba407"
   },
   "outputs": [],
   "source": [
    "merged_scaled.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FLsvWRyxvB22"
   },
   "outputs": [],
   "source": [
    "## Plot histogram distribution of all numerical values in the merged SCALED data\n",
    "\n",
    "# Select only numeric columns and flatten them into a single list, ignoring NaN values\n",
    "numeric_values = merged_scaled.select_dtypes(include='number').values.flatten()\n",
    "numeric_values = numeric_values[~np.isnan(numeric_values)]  # Remove NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y7JdxKu3vB23",
    "outputId": "85eea22b-c54c-44d1-d7b7-18c8d1453e27"
   },
   "outputs": [],
   "source": [
    "len(numeric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "q3ibdS_kvB23",
    "outputId": "c2d71c2e-b1f9-40f9-b447-b854e4be9ee8"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "plt.hist(numeric_values, bins=100)\n",
    "plt.title(\"Scaled Data Values\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GQopYkpm0T7r"
   },
   "outputs": [],
   "source": [
    "# Add back in the \"Group\" column\n",
    "\n",
    "merged_scaled['Group'] = merged_df.set_index('Source Name')[\"Group\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jLUvLxrF3ZP"
   },
   "source": [
    "## All data all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "F5eeZLZSEYj0",
    "outputId": "6a5b0003-f305-42da-99c2-fa59d96d1987"
   },
   "outputs": [],
   "source": [
    "# create heatmap showing which samples have which data types\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(merged_scaled[all_phys + [all_genes[0], all_proteins[0]]].rename(columns={all_genes[0]: 'RNAseq', all_proteins[0]: 'Protein'}),\n",
    "            cmap=sns.color_palette(\"coolwarm\", as_cmap=True))\n",
    "\n",
    "plt.title(\"Data Types\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlation metrics between Tonometry and RNASeq data on only Complete data\n",
    "Check this again on imputed data.\n",
    "Doing only for first few genes for readability of the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(merged_df[all_genes].dropna().corr(),  text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(merged_df[['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes[0:3]].dropna().corr(),  text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTp8gtYU7Q3X"
   },
   "source": [
    "## Impute missing values\n",
    "\n",
    "Since not all measurements are available for all animals, impute the missing values based on the available values.\n",
    "\n",
    "NOTE - this is not necessarily the only thing to do. Feel free to try different approaches.\n",
    "\n",
    "Approach:\n",
    "\n",
    "Using Tonometry data alone to impute RNASeq data. Once satisfied with RNASeq imputation, then we move to imputing all other physiological data again from tonometry data alone.\n",
    "\n",
    "Avoiding imputation from imputed data.\n",
    "\n",
    "Imputation on raw data and not scaled data as part of standard practices - scaling can distort the relationships between variables and potentially lead to biased imputation results, especially when using methods that rely on distance calculations like KNN imputation; by imputing on the original scale, you preserve the true relationships between variables and ensure that the imputed values are more representative of the original data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing RNAseq values based on correlations from Telometry data\n",
    "## Identifying how much data is absent in RNAseq data\n",
    "print(merged_df[all_genes].shape)\n",
    "print(merged_df[all_genes].isna().sum().sum())\n",
    "# 84000 missing values out of 100,000 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEe1HHMkNEbd"
   },
   "source": [
    "### Iterative Imputer\n",
    "\n",
    "This is one option for imputing values. Code is below but commented out for now. The imputed values looked very similar across all samples.\n",
    "\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.impute.IterativeImputer.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "T0sWZt2X8lzm",
    "outputId": "026636b0-6e32-4767-d544-2544ab56c3a1"
   },
   "source": [
    "\n",
    "***A few params to adjust for compute/memory constraints:\n",
    "\n",
    "n_nearest_features (int, default=None)\n",
    "Number of other features to use to estimate the missing values of each feature column. Nearness between features is measured using the absolute correlation coefficient between each feature pair (after initial imputation). To ensure coverage of features throughout the imputation process, the neighbor features are not necessarily nearest, but are drawn with probability proportional to correlation for each imputed target feature. Can provide significant speed-up when the number of features is huge. If None, all features will be used.\n",
    "*Finishes with 15; crashes with 100.\n",
    "\n",
    "max_iter (int, default=10)\n",
    "Maximum number of imputation rounds to perform before returning the imputations computed during the final round. A round is a single imputation of each feature with missing values. The stopping criterion is met once max(abs(X_t - X_{t-1}))/max(abs(X[known_vals])) < tol, where X_t is X at iteration t. Note that early stopping is only applied if sample_posterior=False.\n",
    "\n",
    "skip_complete (bool, default=False)\n",
    "If True then features with missing values during transform which did not have any missing values during fit will be imputed with the initial imputation method only. Set to True if you have many features with no missing values at both fit and transform time to save compute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Approaches with Imputation Alone\n",
    "* Grid Search is used to tune hyper parameters, however it doesn't work with imputer yet since we dont have an estimator established.\n",
    "Few ways to validate the imputer:\n",
    "\n",
    "1. Visually (show below)\n",
    "2. Distribution tests\n",
    "3. Testing the imputer against full data and checking on MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "itera_imp = IterativeImputer(random_state=2, skip_complete=True, n_nearest_features=100, max_iter=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urfUqWBt8uCY"
   },
   "outputs": [],
   "source": [
    "# Completes in ~8 min\n",
    "imp_df = itera_imp.fit_transform(merged_df[['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FifM-2mZ80gR"
   },
   "outputs": [],
   "source": [
    "imp_df = pd.DataFrame(imp_df, columns=['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes)\n",
    "imp_df['Source Name'] = merged_df['Source Name']\n",
    "imp_df['Group'] = merged_df['Group']\n",
    "\n",
    "imp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot heatmap of correlations between RNAseq data and Tonometry data after imputation\n",
    "fig = px.imshow(imp_df[['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes[0:3]].dropna().corr(),  text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ9N213sNTpo"
   },
   "source": [
    "### KNN Imputer\n",
    "\n",
    "Another option for imputing values. Currently using this option.\n",
    "\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.impute.KNNImputer.html\n",
    "\n",
    "Each sample’s missing values are imputed using the mean value from n_neighbors nearest neighbors found in the training set. Two samples are close if the features that neither is missing are close.\n",
    "\n",
    "**Fewer neighbors are better (~2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "-7q_4Th9HxrV"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imp_knn5 = KNNImputer(n_neighbors=5, weights='distance')\n",
    "imp_df_knn5 = imp_knn5.fit_transform(merged_df[['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes])\n",
    "imp_df_knn5 = pd.DataFrame(imp_df_knn5, columns=['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes)\n",
    "imp_df_knn5['Source Name'] = merged_df['Source Name']\n",
    "imp_df_knn5['Group'] = merged_df['Group']\n",
    "\n",
    "imp_knn = KNNImputer(n_neighbors=2, weights='distance')\n",
    "imp_df_knn = imp_knn.fit_transform(merged_df[['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes])\n",
    "imp_df_knn = pd.DataFrame(imp_df_knn, columns=['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes)\n",
    "imp_df_knn['Source Name'] = merged_df['Source Name']\n",
    "imp_df_knn['Group'] = merged_df['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(imp_df_knn5[['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes[0:3]].dropna().corr(),  text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(imp_df_knn[['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes[0:3]].dropna().corr(),  text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sample Imputer\n",
    "This is used in cases where there is more than 25-30% of data to be imputed and is also fast compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi = RandomSampleImputer()\n",
    "imp_df_rsi = rsi.fit_transform(merged_df[['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes])\n",
    "imp_df_rsi = pd.DataFrame(imp_df_rsi, columns=['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes)\n",
    "imp_df_rsi['Source Name'] = merged_df['Source Name']\n",
    "imp_df_rsi['Group'] = merged_df['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(imp_df_rsi[['Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes[0:3]].dropna().corr(),  text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Validation of the Imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RNAseq data from original data\n",
    "rnaseq_original = merged_df[all_genes+['Source Name', 'Group']].melt(id_vars=['Source Name', 'Group'], var_name='Gene', value_name='Expression')\n",
    "rnaseq_itera_imp = imp_df[all_genes+['Source Name', 'Group']].melt(id_vars=['Source Name', 'Group'], var_name='Gene', value_name='Expression')\n",
    "rnaseq_knn_imp = imp_df_knn[all_genes+['Source Name', 'Group']].melt(id_vars=['Source Name', 'Group'], var_name='Gene', value_name='Expression')\n",
    "rnaseq_knn5_imp = imp_df_knn5[all_genes+['Source Name', 'Group']].melt(id_vars=['Source Name', 'Group'], var_name='Gene', value_name='Expression')\n",
    "rnaseq_rsi_imp = imp_df_rsi[all_genes+['Source Name', 'Group']].melt(id_vars=['Source Name', 'Group'], var_name='Gene', value_name='Expression')\n",
    "# Select first five gene to plot\n",
    "gene_to_plot = random.sample(all_genes, 5)\n",
    "for gene in gene_to_plot:\n",
    "    # Filter the data for the selected gene\n",
    "    original_gene_data = rnaseq_original[rnaseq_original['Gene'] == gene]\n",
    "    itera_imp_gene_data = rnaseq_itera_imp[rnaseq_itera_imp['Gene'] == gene]\n",
    "    knn_imp_gene_data = rnaseq_knn_imp[rnaseq_knn_imp['Gene'] == gene]\n",
    "    knn10_imp_gene_data = rnaseq_knn5_imp[rnaseq_knn5_imp['Gene'] == gene]\n",
    "    rsi_imp_gene_data = rnaseq_rsi_imp[rnaseq_rsi_imp['Gene'] == gene]\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    sns.lineplot(data=original_gene_data, x='Source Name', y='Expression', marker='o', label='Original')\n",
    "    sns.lineplot(data=itera_imp_gene_data, x='Source Name', y='Expression', marker='x', linestyle='--', label='Iterative Imputed')\n",
    "    sns.lineplot(data=knn_imp_gene_data, x='Source Name', y='Expression', marker='x', linestyle='dashdot', label='KNN Imputed with 2 Neigbors')\n",
    "    sns.lineplot(data=knn10_imp_gene_data, x='Source Name', y='Expression', marker='x', linestyle='dashdot', label='KNN Imputed with 5 Neigbors')\n",
    "    sns.lineplot(data=rsi_imp_gene_data, x='Source Name', y='Expression', marker='x', linestyle='-.', label='Random Sample Imputed')\n",
    "    plt.title(f'Expression of {gene} Across All Samples')\n",
    "    plt.xlabel('Source Name')\n",
    "    plt.ylabel('Expression')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(title='Impute Method')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE/MSE check with the Complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df[['Source Name','Group','Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes].dropna()[['Source Name','Group','Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']]\n",
    "y = merged_df[['Source Name','Group','Left_1_tonometry',\n",
    "                           'Left_2_tonometry',\n",
    "                           'Left_3_tonometry',\n",
    "                           'Avg_Left_tonometry',\n",
    "                           'Right_1_tonometry',\n",
    "                           'Right_2_tonometry',\n",
    "                           'Right_3_tonometry',\n",
    "                           'Avg_Right_tonometry']+all_genes].dropna()[['Source Name','Group']+all_genes]\n",
    "# There are only 16 samples with complete data for tonometry and RNAseq data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.drop(columns=['Source Name', 'Group']), test_size=0.2, random_state=2)\n",
    "y_test_copy = y_test.copy()\n",
    "y_test_copy = y_test_copy.replace(y_test_copy.values, np.nan)\n",
    "X_test_copy = X_test.copy()\n",
    "X_test_copy = X_test_copy.drop(columns=['Source Name', 'Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itera_imp.fit(pd.concat([X_train.drop(columns=['Source Name', 'Group']), y_train], axis=1))\n",
    "validate_imp_df = itera_imp.transform(pd.concat([X_test_copy, y_test_copy], axis=1))\n",
    "validate_imp_df = pd.DataFrame(validate_imp_df, columns=pd.concat([X_test_copy, y_test_copy]).columns)\n",
    "validate_imp_df['Source Name'] = X_test['Source Name'].reset_index(drop=True)\n",
    "validate_imp_df['Group'] = X_test['Group'].reset_index(drop=True)\n",
    "validate_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi.fit(pd.concat([X_train.drop(columns=['Source Name', 'Group']), y_train], axis=1))\n",
    "validate_rsi_imp_df = rsi.transform(pd.concat([X_test_copy, y_test_copy], axis=1))\n",
    "validate_rsi_imp_df['Source Name'] = X_test['Source Name']\n",
    "validate_rsi_imp_df['Group'] = X_test['Group']\n",
    "\n",
    "itera_imp.fit(pd.concat([X_train.drop(columns=['Source Name', 'Group']), y_train], axis=1))\n",
    "validate_imp_df = itera_imp.transform(pd.concat([X_test_copy, y_test_copy], axis=1))\n",
    "validate_imp_df = pd.DataFrame(validate_imp_df, columns=pd.concat([X_test_copy, y_test_copy]).columns)\n",
    "validate_imp_df['Source Name'] = X_test['Source Name'].reset_index(drop=True)\n",
    "validate_imp_df['Group'] = X_test['Group'].reset_index(drop=True)\n",
    "\n",
    "imp_knn5.fit(pd.concat([X_train.drop(columns=['Source Name', 'Group']), y_train], axis=1))\n",
    "validate_imp_df_knn5 = imp_knn5.transform(pd.concat([X_test_copy, y_test_copy], axis=1))\n",
    "validate_imp_df_knn5 = pd.DataFrame(validate_imp_df_knn5, columns=pd.concat([X_test_copy, y_test_copy]).columns)\n",
    "validate_imp_df_knn5['Source Name'] = X_test['Source Name'].reset_index(drop=True)\n",
    "validate_imp_df_knn5['Group'] = X_test['Group'].reset_index(drop=True)\n",
    "\n",
    "imp_knn.fit(pd.concat([X_train.drop(columns=['Source Name', 'Group']), y_train], axis=1))\n",
    "validate_imp_df_knn = imp_knn.transform(pd.concat([X_test_copy, y_test_copy], axis=1))\n",
    "validate_imp_df_knn = pd.DataFrame(validate_imp_df_knn, columns=pd.concat([X_test_copy, y_test_copy]).columns)\n",
    "validate_imp_df_knn['Source Name'] = X_test['Source Name'].reset_index(drop=True)\n",
    "validate_imp_df_knn['Group'] = X_test['Group'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RNAseq data from original data\n",
    "rnaseq_original = pd.concat([X_test, y_test.drop(columns=['Source Name', 'Group'])], axis=1)[['Source Name', 'Group']+all_genes].melt(id_vars=['Source Name', 'Group'], var_name='Gene', value_name='Expression')\n",
    "rnaseq_itera_imp = validate_imp_df[['Source Name', 'Group']+all_genes].melt(id_vars=['Source Name', 'Group'], var_name='Gene', value_name='Expression')\n",
    "rnaseq_knn_imp = validate_imp_df_knn[['Source Name', 'Group']+all_genes].melt(id_vars=['Source Name', 'Group'], var_name='Gene', value_name='Expression')\n",
    "rnaseq_knn5_imp = validate_imp_df_knn5[['Source Name', 'Group']+all_genes].melt(id_vars=['Source Name', 'Group'], var_name='Gene', value_name='Expression')\n",
    "rnaseq_rsi_imp = validate_rsi_imp_df[['Source Name', 'Group']+all_genes].melt(id_vars=['Source Name', 'Group'], var_name='Gene', value_name='Expression')\n",
    "# Select first five gene to plot\n",
    "gene_to_plot = random.sample(all_genes, 5)\n",
    "for gene in gene_to_plot:\n",
    "    # Filter the data for the selected gene\n",
    "    original_gene_data = rnaseq_original[rnaseq_original['Gene'] == gene]\n",
    "    itera_imp_gene_data = rnaseq_itera_imp[rnaseq_itera_imp['Gene'] == gene]\n",
    "    knn_imp_gene_data = rnaseq_knn_imp[rnaseq_knn_imp['Gene'] == gene]\n",
    "    knn10_imp_gene_data = rnaseq_knn5_imp[rnaseq_knn5_imp['Gene'] == gene]\n",
    "    rsi_imp_gene_data = rnaseq_rsi_imp[rnaseq_rsi_imp['Gene'] == gene]\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    sns.lineplot(data=original_gene_data, x='Source Name', y='Expression', marker='o', label='Original')\n",
    "    sns.lineplot(data=itera_imp_gene_data, x='Source Name', y='Expression', marker='x', linestyle='--', label='Iterative Imputed')\n",
    "    sns.lineplot(data=knn_imp_gene_data, x='Source Name', y='Expression', marker='x', linestyle='dashdot', label='KNN Imputed with 2 Neigbors')\n",
    "    sns.lineplot(data=knn10_imp_gene_data, x='Source Name', y='Expression', marker='x', linestyle='dashdot', label='KNN Imputed with 5 Neigbors')\n",
    "    sns.lineplot(data=rsi_imp_gene_data, x='Source Name', y='Expression', marker='x', linestyle='-.', label='Random Sample Imputed')\n",
    "    plt.title(f'Expression of {gene} Across All Samples')\n",
    "    plt.xlabel('Source Name')\n",
    "    plt.ylabel('Expression')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(title='Impute Method')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate MSE and MAE for each imputation method on the test data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2\n",
    "Build correlation of the gene values based on full dataset per group\n",
    "\n",
    "Store the correlation values and impute the values such that correlation are maintained in each group\n",
    "\n",
    "Reference: https://arxiv.org/pdf/2107.00100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physiological Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lJOOCTz2HWex"
   },
   "outputs": [],
   "source": [
    "# impute the physiological data first\n",
    "\n",
    "imp_phys = imp_knn.fit_transform(merged_scaled[all_phys])\n",
    "imp_phys = pd.DataFrame(imp_phys, columns=all_phys, index=merged_scaled.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvGago31H4Yv"
   },
   "outputs": [],
   "source": [
    "# collect the scaled omics data in 1 df\n",
    "\n",
    "omics_scaled = merged_scaled[[x for x in merged_scaled.columns if x in all_genes or x in all_proteins]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRytk85DIauD"
   },
   "outputs": [],
   "source": [
    "# merge omics_scaled and imp_phys\n",
    "\n",
    "\n",
    "# Merge all DataFrames on \"Source Name\" column\n",
    "temp = pd.merge(imp_phys, omics_scaled, on=\"Source Name\", how=\"outer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GO8BzawJJF54"
   },
   "outputs": [],
   "source": [
    "# impute the omics data using the newly imputed physiological data\n",
    "\n",
    "imp_df_knn = imp_knn.fit_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXG7bUN9IPSH"
   },
   "outputs": [],
   "source": [
    "# Add back in Group column and index (Source Names)\n",
    "\n",
    "imp_df_knn = pd.DataFrame(imp_df_knn, columns=merged_scaled.drop(columns='Group').columns)\n",
    "imp_df_knn.index = merged_scaled.index\n",
    "imp_df_knn['Group'] = merged_scaled['Group']\n",
    "\n",
    "#imp_df_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkNBckekIPVK"
   },
   "outputs": [],
   "source": [
    "## Original code imputing all the data at once\n",
    "\n",
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# imp_knn = KNNImputer(n_neighbors=2, weights='distance')\n",
    "# imp_df_knn = imp_knn.fit_transform(merged_scaled.drop(columns='Group'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REm3sPtFdGbe"
   },
   "source": [
    "## Validating imputation\n",
    "\n",
    "Withold 2 RNAseq samples and impute them (F11 and GC11)\n",
    "\n",
    "Calculate correlation between ground truth RNAseq samples and imputed RNAseq samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2Pek8cKdOBP"
   },
   "outputs": [],
   "source": [
    "# replace F11 and G11 with NaN\n",
    "omics_scaled_del = omics_scaled.copy()\n",
    "omics_scaled_del.loc['F11'] = np.nan\n",
    "omics_scaled_del.loc['GC11'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fm_PJBZ3eTyR"
   },
   "outputs": [],
   "source": [
    "# Impute\n",
    "\n",
    "imp_df_knn_del = imp_knn.fit_transform(pd.merge(imp_phys, omics_scaled_del, on=\"Source Name\", how=\"outer\"))\n",
    "\n",
    "\n",
    "imp_df_knn_del = pd.DataFrame(imp_df_knn_del, columns=merged_scaled.drop(columns='Group').columns)\n",
    "imp_df_knn_del.index = merged_scaled.index\n",
    "imp_df_knn_del['Group'] = merged_scaled['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6Huqc0Mejxd",
    "outputId": "9d69f2b4-04a7-4cb0-a54e-59d9fecabf39"
   },
   "outputs": [],
   "source": [
    "# Calculate correlation\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "f11_real = merged_scaled.drop(columns='Group')[[x for x in merged_scaled.columns if x in rnaseq.columns]].loc['F11']\n",
    "gc11_real = merged_scaled.drop(columns='Group')[[x for x in merged_scaled.columns if x in rnaseq.columns]].loc['GC11']\n",
    "\n",
    "f11_imp = imp_df_knn_del.drop(columns='Group')[[x for x in merged_scaled.columns if x in rnaseq.columns]].loc['F11']\n",
    "gc11_imp = imp_df_knn_del.drop(columns='Group')[[x for x in merged_scaled.columns if x in rnaseq.columns]].loc['GC11']\n",
    "\n",
    "print(spearmanr(f11_real, f11_imp))\n",
    "print(spearmanr(gc11_real, gc11_imp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "CcI0VNH5gJfP",
    "outputId": "26ae01ee-475e-49ed-cc3f-76fa4b66d3a3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# histogram of f11_real overlaid with f11_imp in a different color\n",
    "\n",
    "plt.hist(f11_real, bins=10, alpha=0.5, label='Real')\n",
    "plt.hist(f11_imp, bins=10, alpha=0.5, label='Imputed')\n",
    "plt.ylabel('Number of genes with that expression value')\n",
    "plt.xlabel('Scaled Gene Expression Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uh3vmyLgo2M",
    "outputId": "99113e3a-2f18-4f8a-ebc8-08d006a42be4"
   },
   "outputs": [],
   "source": [
    "len(f11_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FC-EFlcPfc4G",
    "outputId": "dfaf2a2c-dea5-4145-e99a-2e96c6d33e98"
   },
   "outputs": [],
   "source": [
    "f11_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUgSyzxMp0wY"
   },
   "source": [
    "### Comparison of pre/post imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tBuDtWfr3KD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5IeYf6k--k3"
   },
   "source": [
    "#### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "nBefGd4nq_VL",
    "outputId": "12e5edb2-5d1f-41fe-e49d-9f111b391a40"
   },
   "outputs": [],
   "source": [
    "# RNAseq data pre-imputation\n",
    "\n",
    "df = merged_scaled.drop(columns='Group')[all_genes]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df,\n",
    "            cmap=sns.color_palette(\"coolwarm\", as_cmap=True))\n",
    "            #mask=df.isnull()\n",
    "\n",
    "\n",
    "plt.title(\"RNAseq pre-imputation\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "NOgOEDln6GlR",
    "outputId": "25bcf1b3-68c4-43e8-82cf-7bcff8f32dc8"
   },
   "outputs": [],
   "source": [
    "# RNAseq data post-imputation\n",
    "\n",
    "df = imp_df_knn.drop(columns='Group')[all_genes]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df,\n",
    "            cmap=sns.color_palette(\"coolwarm\", as_cmap=True))\n",
    "\n",
    "plt.title(\"RNAseq post-imputation\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780
    },
    "id": "w7dWj1v32_aL",
    "outputId": "510215b2-705a-4bca-9fea-aac904451c31"
   },
   "outputs": [],
   "source": [
    "# Protein data pre-imputation\n",
    "\n",
    "df = merged_scaled.drop(columns='Group')[all_proteins]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df,\n",
    "            cmap=sns.color_palette(\"coolwarm\", as_cmap=True))\n",
    "\n",
    "plt.title(\"Protein data pre-imputation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780
    },
    "id": "HKQ8qL1e3JCr",
    "outputId": "e9b1c4c9-f8e0-4ae5-ddd7-f009300783e6"
   },
   "outputs": [],
   "source": [
    "# Protein data post-imputation\n",
    "\n",
    "df = imp_df_knn.drop(columns='Group')[all_proteins]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df,\n",
    "            cmap=sns.color_palette(\"coolwarm\", as_cmap=True))\n",
    "\n",
    "plt.title(\"Protein data post-imputation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "id": "41oZAtKfp--u",
    "outputId": "f1f65210-1125-4dea-e2d7-cd8061d8f0a7"
   },
   "outputs": [],
   "source": [
    "# Physiological data pre-imputation\n",
    "\n",
    "df = merged_scaled.drop(columns='Group')\n",
    "df = df[all_phys]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df,\n",
    "            cmap=sns.color_palette(\"coolwarm\", as_cmap=True))\n",
    "\n",
    "plt.title(\"Physiological data pre-imputation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "id": "3jshae5Ep_Hn",
    "outputId": "190dcb1e-f277-43f9-ab94-91bfad6229f8"
   },
   "outputs": [],
   "source": [
    "# Physiological data post-imputation\n",
    "\n",
    "df = imp_df_knn.drop(columns='Group')\n",
    "df = df[all_phys]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df,\n",
    "            cmap=sns.color_palette(\"coolwarm\", as_cmap=True))\n",
    "\n",
    "plt.title(\"Physiological data post-imputation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZ9KFAiWwE1e"
   },
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMARDRlqw3YQ"
   },
   "outputs": [],
   "source": [
    "group_colors = {'GC': 'green', 'F': 'blue', 'Viv': 'red', 'CC1': 'purple', 'CC2': 'orange'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50WzltOe0Vzs"
   },
   "source": [
    "**Most DE gene - ENSMUSG00000008348**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "dSARfFWR0Rpk",
    "outputId": "7ddc1092-94f9-4b97-fc9a-6c0b6b877bac"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=merged_df, x='ENSMUSG00000008348', hue='Group', bins=10, multiple='stack', palette=group_colors)\n",
    "plt.title('ENSMUSG00000008348 Pre-Imputation')\n",
    "plt.xlabel('Gene Counts')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "t4vSYmTl0RsO",
    "outputId": "5ff6139b-7bbb-4fa2-c961-6b631ef2ee35"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=imp_df_knn, x='ENSMUSG00000008348', hue='Group', bins=10, multiple='stack', palette=group_colors)\n",
    "plt.title('ENSMUSG00000008348 Post-Imputation')\n",
    "plt.xlabel('Gene Counts')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx0qfq17__rW"
   },
   "source": [
    "**A physiological measurement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "6KQkcvqf0RvD",
    "outputId": "df382b99-bbe9-44ef-9a68-5b71cd66de83"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=merged_df, x='Total_Area_tunel', hue='Group', bins=10, multiple='stack', palette=group_colors)\n",
    "plt.title('TUNEL Pre-Imputation')\n",
    "plt.xlabel('Gene Counts')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "LdefPprnAG5i",
    "outputId": "9796e809-02b0-4b10-bf8f-bee5f05058c1"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=imp_df_knn, x='Total_Area_tunel', hue='Group', bins=10, multiple='stack', palette=group_colors)\n",
    "plt.title('ENSMUSG00000008348 Post-Imputation')\n",
    "plt.xlabel('Gene Counts')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1wMBHjmKFDV"
   },
   "source": [
    "#### PCA\n",
    "\n",
    "Let's look at the relationships between samples using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vLMhjIcKG14"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7pNaqzHn2bm"
   },
   "outputs": [],
   "source": [
    "def pcaFcn(input_df, title):\n",
    "\n",
    "  # Separate features and group\n",
    "  X = df.drop(columns=['Group'])  # Drop the 'Group' column to get features\n",
    "  y = df['Group']  # Extract the 'Group' column\n",
    "\n",
    "  # Standardize the features\n",
    "  X_standardized = StandardScaler().fit_transform(X)\n",
    "\n",
    "  # Perform PCA\n",
    "  pca = PCA(n_components=2)\n",
    "  X_pca = pca.fit_transform(X_standardized)\n",
    "\n",
    "  # Create a DataFrame for the PCA results\n",
    "  pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "  pca_df['Group'] = y.values  # Add the group column\n",
    "\n",
    "  # Plotting\n",
    "\n",
    "  group_colors = {'GC': 'green', 'F': 'blue', 'Viv': 'red', 'CC1': 'purple', 'CC2': 'orange'}  # Define a custom color mapping for each \"Group\" label\n",
    "\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='Group', palette=group_colors, s=100, alpha=0.5)\n",
    "  #sns.stripplot(data=pca_df, x='PC1', y='PC2', hue='Group', palette=group_colors, s=10, jitter=True, dodge=True) # Tried using stripplot because of overlapping points\n",
    "  plt.title(title)\n",
    "  plt.xlabel('Principal Component 1')\n",
    "  plt.ylabel('Principal Component 2')\n",
    "  plt.legend(title='Group')\n",
    "  plt.grid(False)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "ykrUl01xba-7",
    "outputId": "35fad6e7-a449-4a4d-c133-60f6dd512ecb"
   },
   "outputs": [],
   "source": [
    "# All imputed data\n",
    "\n",
    "df = imp_df_knn\n",
    "\n",
    "pcaFcn(df, 'RR9 All Data (Includes Imputed)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "k5temR0KKOtJ",
    "outputId": "7069c8de-81c2-453c-f1ba-92344e6e5528"
   },
   "outputs": [],
   "source": [
    "# RNAseq data alone - imputed\n",
    "\n",
    "columns_list = all_genes.copy()\n",
    "columns_list.append('Group')\n",
    "df = imp_df_knn[columns_list]\n",
    "\n",
    "pcaFcn(df, 'RR9 RNAseq Data (Includes Imputed)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "McGmnhxcuEKH",
    "outputId": "53d40ca5-b908-472c-ffe3-029b789aad40"
   },
   "outputs": [],
   "source": [
    "# RNAseq data alone - imputed and colored by yes/no imputed sample\n",
    "\n",
    "imputed_samples = []\n",
    "for x in imp_df_knn.index:\n",
    "  if x in rnaseq['Source Name'].values:\n",
    "    imputed_samples.append('No')\n",
    "  else:\n",
    "    imputed_samples.append('Yes')\n",
    "\n",
    "\n",
    "columns_list = list(rnaseq.drop(columns='Source Name').columns)\n",
    "df = imp_df_knn[columns_list]\n",
    "df['Imputed'] = imputed_samples\n",
    "\n",
    "\n",
    "# Separate features and group\n",
    "X = df.drop(columns=['Imputed'])\n",
    "y = df['Imputed']\n",
    "\n",
    "# Standardize the features\n",
    "X_standardized = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_standardized)\n",
    "\n",
    "# Create a DataFrame for the PCA results\n",
    "pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['Imputed'] = y.values\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "#sns.stripplot(data=pca_df, x='PC1', y='PC2', hue='Imputed', palette={'Yes': 'orange', 'No': 'blue'}, s=10, jitter=True, dodge=True)\n",
    "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='Imputed', palette={'Yes': 'orange', 'No': 'blue'}, s=100, alpha=0.5)\n",
    "\n",
    "plt.title('RR9 RNAseq Data (Imputed) - colored by Imputed')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Imputed')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "M4q-MCb7Rg3l",
    "outputId": "96f1caf8-7f95-48c7-8255-712d07846f48"
   },
   "outputs": [],
   "source": [
    "# RNAseq data alone - non imputed\n",
    "\n",
    "rnaseq_pca = rnaseq.copy()\n",
    "rnaseq_pca['Group'] = ['GC','GC','GC','GC','GC','GC','GC','GC','F','F','F','F','F','F','F','F']\n",
    "df = rnaseq_pca.drop(columns=['Source Name'])\n",
    "\n",
    "pcaFcn(df, 'RR9 RNAseq Data (Non-Imputed)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "dG-LSNxS4oIA",
    "outputId": "52b701dc-e8c6-472e-c6b0-5d2c65d6d9fc"
   },
   "outputs": [],
   "source": [
    "# Protein data alone - imputed\n",
    "\n",
    "columns_list = all_proteins.copy()\n",
    "columns_list.append('Group')\n",
    "df = imp_df_knn[columns_list]\n",
    "\n",
    "pcaFcn(df, 'RR9 Protein Data (Includes Imputed)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "hFg8NICLKRZW",
    "outputId": "b125e4a5-356a-4d4f-8003-a988af04ee63"
   },
   "outputs": [],
   "source": [
    "# Physiological data alone - imputed\n",
    "\n",
    "df = imp_df_knn[[x for x in imp_df_knn.columns if x not in all_genes and x not in all_proteins]]\n",
    "df['Group'] = imp_df_knn['Group']\n",
    "\n",
    "pcaFcn(df, 'RR9 Physiological Data (Includes Imputed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9kHosTf8I1j"
   },
   "source": [
    "# Metadata Preparation\n",
    "\n",
    "Prepare a master dataframe of metadata for all samples.\n",
    "\n",
    "Using the Metadata API from the OSDR API: https://www.nasa.gov/reference/osdr-public-api/#hds-sidebar-nav-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dou7exSr80nq",
    "outputId": "20fec697-eedb-4bd5-f4d2-c4d84e4cbe7e"
   },
   "outputs": [],
   "source": [
    "# Use OSD-583 (tonometry) since that study contains measurements (and metadata) from all the animals\n",
    "\n",
    "response = requests.get('https://osdr.nasa.gov/osdr/data/osd/meta/583').json() # pull metadata from API https://www.nasa.gov/reference/osdr-public-api/#hds-sidebar-nav-3\n",
    "\n",
    "# empty df and lists for columns\n",
    "meta = pd.DataFrame()\n",
    "\n",
    "sample_names = []\n",
    "sex = []\n",
    "mission_weeks = []\n",
    "diet = []\n",
    "group = []\n",
    "\n",
    "for sam in response['study']['OSD-583']['studies'][0]['materials']['samples']:\n",
    "  sample_names.append(sam['name'])\n",
    "  sex.append(sam['characteristics'][3]['value']['annotationValue'])\n",
    "  mission_weeks.append(sam['characteristics'][4]['value'])\n",
    "  diet.append(sam['characteristics'][5]['value'])\n",
    "  group.append(sam['factorValues'][0]['value']['annotationValue'])\n",
    "\n",
    "\n",
    "meta['Sample Name'] = sample_names\n",
    "meta['Sex'] = sex\n",
    "meta['Mission Length Weeks'] = mission_weeks\n",
    "meta['Diet'] = diet\n",
    "meta['Group'] = group\n",
    "\n",
    "# add source name column to match the data df\n",
    "meta['Sample Name'] = meta['Sample Name'].str.replace('CC2_', 'CC2')\n",
    "meta['Source Name'] = meta['Sample Name'].str.split('_').str[0]\n",
    "meta['Source Name'] = meta['Source Name'].str.replace('FViv', 'CC1_')\n",
    "meta['Source Name'] = meta['Source Name'].str.replace('CC2', 'CC2_')\n",
    "meta.drop(columns='Sample Name', inplace=True)\n",
    "meta = meta.rename(columns={'Source Name': 'sample'}) # rename to \"sample\" since GAN expects it\n",
    "meta = meta.set_index('sample')\n",
    "\n",
    "\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7AtiskU5H8v"
   },
   "source": [
    "# Synthetic Data Generation\n",
    "\n",
    "Use a Generative Adversarial Network (GAN) to generate synthetic data.\n",
    "\n",
    "https://github.com/nasa/AI4LS/tree/gan-pub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LXtcyY4W2fh",
    "outputId": "0cef80ff-c105-4061-c9c1-316d0ef87970"
   },
   "outputs": [],
   "source": [
    "## Mount Google Drive for writing out files\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pze7FARcXLOf",
    "outputId": "436a4eb9-ac90-4f56-9098-6c10d63d4821"
   },
   "outputs": [],
   "source": [
    "## Change to the desired output directory\n",
    "\n",
    "%cd \"/content/drive/My Drive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRa0R1va0zat",
    "outputId": "ce10a2fe-a237-4391-e051-f6387b2a9bec"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxABPgUp5eEm",
    "outputId": "60750301-ed2a-42e4-a638-1542054eb6f0"
   },
   "outputs": [],
   "source": [
    "## Clone the GAN repo (uncomment if you have not cloned it before)\n",
    "\n",
    "#!git clone -b gan-pub --single-branch https://github.com/nasa/AI4LS.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pASWnYM8BeB"
   },
   "outputs": [],
   "source": [
    "# sort data and metadata by sample/source name\n",
    "\n",
    "imp_df_knn = imp_df_knn.sort_index()\n",
    "meta = meta.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cyWB61wmMeA"
   },
   "outputs": [],
   "source": [
    "#imp_df_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5t4e9c3YF-mq"
   },
   "outputs": [],
   "source": [
    "# write to csv for GAN program to find\n",
    "\n",
    "meta.to_csv('meta.csv')\n",
    "\n",
    "imp_df_knn.drop(columns='Group').transpose().to_csv('imp_df_knn.csv', index=True, index_label='gene') # name the index \"gene\" because GAN expects it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvTHqs0a2Iay",
    "outputId": "b695c9a1-8f1c-4936-c5bf-498d6baf69a3"
   },
   "outputs": [],
   "source": [
    "# reduce dims\n",
    "\n",
    "# python 3.8\n",
    "\n",
    "'''\n",
    "-n option specifies the number of genes with the highest variance to keep\n",
    "-c option specifies the coefficient of variation below which genes are removed\n",
    "-a option specifies the percentage threshold (out of 100) of genes with zero expression above which genes are removed\n",
    "-e option specifies the input expression file.\n",
    "-t option specifies gene type, may be one of the following:\n",
    "'''\n",
    "\n",
    "# If you use this script, comment out the function calls for convertIdsToNames() and filterGenesByType() and the pybiomart import statement\n",
    "\n",
    "#!python AI4LS/utils/reduceDim.py -e imp_df_knn.csv -n 10000 -a 90 -t protein_coding -c 1.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddSie37AE926",
    "outputId": "410d2cce-75b4-433c-96bb-58221d7cc065"
   },
   "outputs": [],
   "source": [
    "# increase the number of technical replicates\n",
    "\n",
    "'''\n",
    "-e specifies the input expression file\n",
    "-m specifies the input metadata file\n",
    "-n specifies the number of times more samples to create\n",
    "-v specifies the variance to use for the zero-mean gaussian sampling - IS THIS REALLY USED?\n",
    "-k specifies the metadata key\n",
    "'''\n",
    "\n",
    "!python NASA/utils/statistically_technical_replicate.py \\\n",
    "-e imp_df_knn__reduced__t_protein_coding_a_0.9_c_1.5_n_1000.csv \\\n",
    "-m meta.csv \\\n",
    "-n 50 \\\n",
    "-v 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jd7CvX_TQcSi"
   },
   "outputs": [],
   "source": [
    "# create a meta JSON file to indicate which meta data are numerical and which are categorical\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"cat\": [\"Sex\", \"Diet\", \"Group\"],\n",
    "    \"num\": [\"Mission Length Weeks\"]\n",
    "}\n",
    "\n",
    "filename = \"meta.json\"\n",
    "\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxifnUmYgVXd",
    "outputId": "5fc2afcc-b96a-4f8f-d7ad-c77270b04c75"
   },
   "outputs": [],
   "source": [
    "# Create the output folder\n",
    "\n",
    "!mkdir gan-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "baQgAOuoFs5i",
    "outputId": "26d44104-32fd-431c-9b46-c9aab4a8714d"
   },
   "outputs": [],
   "source": [
    "# This may work when run on command line instead of Google Colab\n",
    "\n",
    "'''\n",
    "-ie is the input expression file\n",
    "-im is the input metadata file\n",
    "-od is the output directory\n",
    "-umf is the JSON file defining which categorical and numerical values to use\n",
    "-e is the number of epochs\n",
    "-s is the seed for the random number generator\n",
    "-cd is the checkpoint directory\n",
    "'''\n",
    "\n",
    "\n",
    "!python NASA/GAN/gen_fake_expr.py \\\n",
    "-ie imp_df_knn__reduced__t_protein_coding_a_0.9_c_1.5_n_1000.csv  \\\n",
    "-im meta__expanded_50_10.0.csv \\\n",
    "-od /gan-out  \\\n",
    "-umf meta.json \\\n",
    "-e 10 \\\n",
    "-s 23 \\\n",
    "-cd /gan-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRe3PiL_bZk2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "S_tO0FkNge42",
    "outputId": "cd236f55-3f79-44c7-c777-bb47d1a5b9e6"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hcKs_ETbXsk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
